\chapter{Introduction}
\label{ch:intro}

\section{Background}

IRs (Intermediary Representations) are used across different stages of compilation 
in order to work at different levels of abstraction. This allows high level 
optimizations to be applied on a high level view of the code, while letting low 
level optimizations (like instruction selection) be handled close to the ISA. 

There is a lot of work needed to optimize these IRs but if programs can be proven equivalent 
(for example, by leveraging formal semantics) a technique arises called superoptimization. 
By enumerating all programs of a small size we may find a shorter program that is equivalent 
to a larger one  a larger one\textsuperscript{citation needed}. This technique can be applied 
across IRs, the target could even be an ISA. Therefore we can use superoptimization to find lowerings 
from a source IR (like LLVM IR) to an assembly language like RISC-V. Hence I'll refer to 
this as backend synthesis.

\section{Motivation}

Why go through the effort of providing formal semantics for your IR when you could just
go ahead and write the lowering yourself? Well, manually written backends are quite 
buggy. Additionally, with proper tools and support compiler developers will have an easier time
defining the semantics of their IRs.

\begin{figure}[H] 
    \centering
    \includegraphics[width=1\textwidth]{intro/BugsInLLVM.png}
    \caption{The overall evolution of bugs in the LLVM repository. The area in gray shows
		new bugs reported every month. \cite{compiler-bugs}}
    \label{fig:bugs_llvm}
\end{figure}
\stefan{Don't know if this is the best graph to show backend bugs}

Luckily, there exist verification tools that can prove the correctness of a lowering for 
which semantics are available \cite{smt-mlir}. However these require the compiler 
developer to both specify the semantics for their source and target representations, while 
also providing the lowering themselves. This is increases the overall amount of work 
required of the compiler developer.


The aim of this project is to give motivation for compiler developers to provide formal
bitvector semantics for their IRs by synthesizing a large portion of the backend. The
synthesized lowering will also verified so no additional work will be required for correctness.
Moreover, the synthesized lowering will use the minimal number of assembly instruction for
each IR instruction to achieve high performance.

Thus this project introduces a prototype of backend synthesis to a subset RISC-V, 
evaluating its effectiveness, as well as some optimization techniques that can be 
applied to speed up the process, achieving more coverage of the source representation,
and a more performant backend, all while being proven correct.


\section{Approach}

For easier development, prototyping and experimenting I will be using the 
xDSL\textsuperscript{citation needed} framework which contains an implementation
of a RISC-V dialect, as well as making use of the infrastructure in the open source project 
xdsl-smt, an implementation of SMTLib for xDSL, and mlir-fuzz, which is used for 
enumerating mlir programs. 

The project consists \stefan{WIP} of a series of contributions to these projects to add
lower the RISC-V dialect to the smt dialect and formally prove equivalence to some 
authoritative RISC-V semantics, enhance mlir-fuzz to generate RISC-V programs, then run
the enumerative synthesis, generating a backend for LLVM IR, evaluate the coverage and 
performance of the synthesized lowering.

Following this the aim is to experiment with various optimizations to increase synthesis
speed, increase coverage or performance.\stefan{Experiments and optimizations are WIP}

\section{Previous Work}
This project is based of work done by my supervisor Mathieu Fehr \stefan{there should
probably be more credits here} on xdsl-smt, and mlir-fuzz. It uses open source 
lean semantics\textsuperscript{citation needed} proven equivalent to the authoritative SAIL 
semantics\textsuperscript{citation needed}. 
Superoptimization is a well known technique utilized successfully in projects such as
Souper \cite{souper}.


\clearpage
\chapter{Preparation}
\label{ch:prep}
\section{MLIR}

MLIR (Multi-Level Intermediate Representation) is an extensible framework that allows
users to define extensible and composable IRs called dialects. These dialects leverage
SSA (Static Single Assignment) form, where each program is made out of operations, 
each with some number of operands and results. MLIR operations also have attributes,
which are bits of data that are part of the program (i.e the values of constants) that
are stored as a name to value dictionary.

In order to make dataflow information explicit, the IRs enforce static single assignment
so each operation's results are assigned to unique values.

\subsection*{xDSL}
Troughout the project I will be using the xDSL compiler framework \cite{xdsl} which is 
interoperable with MLIR, but is written in Python to allow for rapid prototyping. The IR files for
both xdsl and mlir both use the same format, so existing tools build for MLIR can still be used.

\subsection*{LLVM IR}

LLVM set of compiler and toolchains technologies that leverages a language-independent 
intermediate representation (LLVM IR). It will serve as the source of our backend synthesis
as it is widely used and would make a great example.

In particular, I will be targeting the arithmetic subset LLVM IR, as these instructions can
be modeled with bitvector SMT semantics.

Here is an example of a function that checks whether their arguments are equal:
\begin{minted}{mlir}
func.func @main(%arg0 : i64, %arg1 : i64) -> i1 {
    %0 = llvm.icmp eq, %arg0, %arg1 : i64
    func.return %0 : i1
 }
\end{minted}


\subsection*{RISC-V}

Below is an example of a function written in the RISC-V dialect of xDSL. It's operations
are equivalent to a RISC-V assembly instructions, but the code is in SSA form.

We can also refer to specific registers as part of the type attribute, although this
is unnecesary and better handled by a register allocator.

\begin{minted}{mlir}
func.func @main(%arg0 : !riscv.reg, %arg1 : !riscv.reg) -> !riscv.reg {
  %0 = riscv.sub %arg0, %arg1 : (!riscv.reg, !riscv.reg) -> !riscv.reg
  %1 = riscv.sltiu %0, 1 : (!riscv.reg) -> !riscv.reg
  func.return %1 : !riscv.reg
}
\end{minted}

This will be the target of our backend synthesis, as it has a small base instruction set 
and extensions can be added as the scope of the project grows.

\subsection*{IRDL}

IRDL (IR Definition Language) \cite{irdl} is a dialect that is used to define dialects.
This is useful to define the structure of our source and target dialect to a fuzzer,
a tool that will generate programs using the defined operations.
\begin{minted}{mlir}
// Structure of an llvm.and operation
irdl.operation @and {
  %integer = irdl.is i64
  irdl.operands(operand0: %integer, operand1: %integer)
  irdl.results(result0: %integer)
}
\end{minted}
\subsection*{PDL}

PDL (Pattern Definition Language) is a dialect used in order to define rewrite
patterns. Such patterns can be used in order to transform code.

For example a the PDL pattern below converts the LLVM IR equality example above into the RISC-V 
instructions below.
\begin{minted}{mlir}
pdl.pattern : benefit(1) {
  %0 = pdl.type : i64
  %1 = pdl.operand : %0
  %2 = pdl.operand : %0
  %3 = pdl.attribute = 0 : i64
  %4 = pdl.type : i1
  %5 = pdl.operation "llvm.icmp" (%1, %2 : !pdl.value, !pdl.value)
       {"predicate" = %3} -> (%4 : !pdl.type)
  %6 = pdl.result 0 of %5
  pdl.rewrite %5 {
    %7 = pdl.type : !riscv.reg
    %8 = pdl.operation "riscv.sub" (%1, %2 : !pdl.value, !pdl.value) -> (%7 : !pdl.type)
    %9 = pdl.result 0 of %8
    %10 = pdl.attribute = 1 : si12
    %11 = pdl.operation "riscv.sltiu" (%9 : !pdl.value) {"immediate" = %10} -> (%7 : !pdl.type)
    %12 = pdl.result 0 of %11
    pdl.replace %5 with (%12 : !pdl.value)
  }
}
\end{minted}
\stefan{Maybe put code examples in an Appendix}

\section{Semantics}
\subsection{SMT dialect}
\subsection{Translation Validation}

\subsection{Refinements}
Poison.

\section{Superoptimization}
\fehr{I would probably swap these two sections. Lowering synthesis as a general concept, and
then MLIR-fuzz as a tool to at least do the enumeration part of it.}
\subsection{MLIR-fuzz}
\subsection{Lowering Synthesis}

\section{Formal Verification}
\subsection{Formal Specification of ISA Semantics}
\subsection{Proofs of Equivalence}

\section{Requirements Analysis}

This section should contain the requirements of the project, followed by a plan
to achieve those requirements within a real timeline.

There should be leftover time to iterate, optimize and experiment.

\section{Software Engineering}

\subsection{Development Model}
Spiral

\subsection{Languages and Tools}
Python, Pylance, C++, Clang, Ninja, MLIR, xDSL, xdsl-smt, mlir-fuzz, z3, Git, GitHub
\fehr{If you have Python and Pylance, should you also have C++ and clang? Ninja for
building mlir-fuzz also?}

\subsection{Open Source Contributions}
\section{Starting Point}
Knowledge of C++, Knowledge of Python
\fehr{Probably would add some knowledge on compilers or something not language related?}

\clearpage
\chapter{Implementation}
\stefan{I think I need to add more content here. This should be my main focus after
completing some basic evaluation}
\label{ch:impl}
\section{Base RISC-V to SMT Semantics}
\subsection{Registers as MLIR Types}
\fehr{What is it supposed to be? Shouldn't it be in preparation?}
\subsection{Immediates and Attributes}
\section{SMT to Lean4}
\subsection{Bitvector Operations}
\subsection{Generating theorems with bv\_decide}
\section{RISC-V Enumeration}
\subsection{RISC-V in IRDL}
\subsection{Synthetic Operations}
\section{Backend Synthesis}
\subsection{Refinements}
\subsection{Multithreaded Iterative Deepening}
I don't really know if the title works, here I'd talk about how I attempt to lower to lower
sizes first, and have a pool of workers do so in parallel.
\subsection{Conversion to PDL}
The functions obtained from the enumerative search are then converted into PDL Patterns.
\section{Pruning the searchspace}
This section will detail attempts at optimization that will hopefully succeed.
\section{Repository Overview}

\clearpage
\chapter{Evaluation}
\label{ch:eval}
\section{Correctness}

\subsection{Semantics correctness}
The semantics are proven equivalent to authoritative SAIL semantics in Lean.

\subsection{PDL Transformations}
The pdl transformations are proven equivalent using an smt solver.

\section{Synthesis duration analysis}

\subsection{Choosing Refinements}

\subsection{Effects of TBD optimization}

\section{Coverage of LLVM IR instructions}

\subsection{Base RISC-V instruction set}

\subsection{Bit Manipulation Extension}

\subsection{Multiplication and Division Extension}

\section{Performance against LLVM}




\clearpage
\chapter{Conclusion}
\label{ch:conc}

\section{Work Completed}

\subsection{Synthesized large chunk of LLVM to RISC-V Backend}

\subsection{Examined optimizations techniques for backend synthesis}

\subsection{Novel Contribution}
Here I don't know what to count as ``novel'' but hopefully there's
something I can write here.

\section{Future Work}
One thing I'll talk about here is making this a proper tool written in
a performance oriented language like C++.
More things as ideas arise.

\section{Reflections}
Waffling about things I learnt, with a focus on working on an open source
project, and how it's different from a personal project.

